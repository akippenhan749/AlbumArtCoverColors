{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2547/2547 [00:12<00:00, 201.56it/s]\n",
      "  3%|▎         | 22/637 [00:00<00:02, 214.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images: (2547, 200, 150, 3)\n",
      "Shape of labels: (2547, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 637/637 [00:03<00:00, 209.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images: (637, 200, 150, 3)\n",
      "Shape of labels: (637, 6)\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mean\n",
    "import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process and arrange image data\n",
    "def arrange_data(df):\n",
    "    \n",
    "    image_data = []\n",
    "    img_paths = np.asarray(df.iloc[:, 0]) #First column is the image paths\n",
    "    \n",
    "    for i in tqdm(range(len(img_paths))):\n",
    "    \n",
    "            \n",
    "        img = tf.keras.utils.load_img(img_paths[i],target_size=(200, 150, 3))\n",
    "        img = tf.keras.utils.img_to_array(img)\n",
    "        img = img/255\n",
    "        image_data.append(img)\n",
    "        \n",
    "        \n",
    "    X = np.array(image_data)\n",
    "    Y = np.array(df.iloc[:,1:7])\n",
    "    \n",
    "    print(\"Shape of images:\", X.shape)\n",
    "    print(\"Shape of labels:\", Y.shape)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('trainingData.csv')\n",
    "\n",
    "# Modifying image path column\n",
    "train_df['Image Path'] = train_df['Image Path'].str.replace('/Users/johnhope/Desktop/GitHub/AlbumArtCoverColors/data/','')\n",
    "train_df['Image Path'] = train_df['Image Path'].str.replace('/images','')\n",
    "\n",
    "X_train, Y_train = arrange_data(train_df)\n",
    "\n",
    "test_df = pd.read_csv('testingData.csv')\n",
    "\n",
    "test_df['Image Path'] = test_df['Image Path'].str.replace('/Users/johnhope/Desktop/GitHub/AlbumArtCoverColors/data/','')\n",
    "test_df['Image Path'] = test_df['Image Path'].str.replace('/images','')\n",
    "\n",
    "X_test, Y_test = arrange_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 6, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12288)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              12583936  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,304,774\n",
      "Trainable params: 19,669,510\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jah9kqn/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "<ipython-input-3-39f536020218>:42: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(aug.flow(X_train, Y_train, batch_size=BS),validation_data=(X_test, Y_test),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 388s 10s/step - loss: 0.4823 - accuracy: 0.1917 - val_loss: 0.4489 - val_accuracy: 0.2151\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 386s 10s/step - loss: 0.4526 - accuracy: 0.2280 - val_loss: 0.4494 - val_accuracy: 0.2465\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 386s 10s/step - loss: 0.4440 - accuracy: 0.2541 - val_loss: 0.4495 - val_accuracy: 0.2166\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 386s 10s/step - loss: 0.4382 - accuracy: 0.2872 - val_loss: 0.4437 - val_accuracy: 0.2433\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 388s 10s/step - loss: 0.4327 - accuracy: 0.2857 - val_loss: 0.4456 - val_accuracy: 0.2402\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 387s 10s/step - loss: 0.4240 - accuracy: 0.3137 - val_loss: 0.4383 - val_accuracy: 0.2873\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 386s 10s/step - loss: 0.4112 - accuracy: 0.3645 - val_loss: 0.4595 - val_accuracy: 0.2104\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 386s 10s/step - loss: 0.4065 - accuracy: 0.3754 - val_loss: 0.4601 - val_accuracy: 0.2496\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 386s 10s/step - loss: 0.3932 - accuracy: 0.3951 - val_loss: 0.4648 - val_accuracy: 0.2747\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 385s 10s/step - loss: 0.3838 - accuracy: 0.4293 - val_loss: 0.4505 - val_accuracy: 0.2794\n"
     ]
    }
   ],
   "source": [
    "num_classes = 6  # Number of genres\n",
    "\n",
    "# Import architecture\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# Load VGG model\n",
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(200,150, 3))\n",
    "\n",
    "# Freeze the layers except the last 4 layers\n",
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the vgg convolutional base model\n",
    "model.add(vgg_conv)\n",
    "\n",
    "# Add layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Construct training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,width_shift_range=0.2, height_shift_range=0.2, \n",
    "                         shear_range=0.15,horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# Train the network\n",
    "EPOCHS= 10\n",
    "BS = 64\n",
    "\n",
    "history = model.fit_generator(aug.flow(X_train, Y_train, batch_size=BS),validation_data=(X_test, Y_test), \n",
    "                    steps_per_epoch=len(X_train) // BS, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for testing\n",
    "model.save('Model_4d.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
